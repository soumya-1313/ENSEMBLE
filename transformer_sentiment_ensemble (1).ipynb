{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Sentiment Analysis with 9 Transformer Models and Ensemble\n", "This notebook runs 9 pre-trained transformer models on the IMDB dataset and compares them based on evaluation metrics including sensitivity, specificity, precision, recall, F1, and accuracy. Finally, an ensemble model is built using majority voting."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies\n", "!pip install transformers datasets scikit-learn\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n", "from datasets import load_dataset\n", "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n", "from collections import Counter\n", "import torch\n", "\n", "models = [\n", "    'bert-base-uncased',\n", "    'distilbert-base-uncased',\n", "    'roberta-base',\n", "    'albert-base-v2',\n", "    'xlnet-base-cased',\n", "    'google/electra-base-discriminator',\n", "    'camembert-base',\n", "    'microsoft/deberta-base',\n", "    'flaubert/flaubert_base_cased'\n", "]\n", "\n", "# Load IMDB dataset and reduce size for speed\n", "dataset = load_dataset(\"imdb\")\n", "test_data = dataset['test'].select(range(200))\n", "\n", "def get_metrics(y_true, y_pred):\n", "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n", "    sensitivity = tp / (tp + fn)\n", "    specificity = tn / (tn + fp)\n", "    precision = precision_score(y_true, y_pred)\n", "    recall = recall_score(y_true, y_pred)\n", "    f1 = f1_score(y_true, y_pred)\n", "    accuracy = accuracy_score(y_true, y_pred)\n", "    return sensitivity, specificity, precision, recall, f1, accuracy\n", "\n", "results = []\n", "predictions_all = []\n", "\n", "for model_name in models:\n", "    try:\n", "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n", "        pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n", "        \n", "        preds = []\n", "        for text in test_data['text']:\n", "            result = pipe(text[:512])[0]['label']\n", "            preds.append(1 if 'POS' in result or 'LABEL_1' in result else 0)\n", "        \n", "        predictions_all.append(preds)\n", "        y_true = test_data['label']\n", "        metrics = get_metrics(y_true, preds)\n", "        results.append((model_name, *metrics))\n", "    except Exception as e:\n", "        print(f\"Model {model_name} failed: {e}\")\n", "        continue\n", "\n", "# Ensemble Voting\n", "ensemble_preds = []\n", "for i in range(len(test_data)):\n", "    votes = [pred[i] for pred in predictions_all if len(pred) == len(test_data)]\n", "    ensemble_preds.append(Counter(votes).most_common(1)[0][0])\n", "\n", "ensemble_metrics = get_metrics(test_data['label'], ensemble_preds)\n", "results.append((\"Ensemble\", *ensemble_metrics))\n", "\n", "# Convert to DataFrame\n", "df_results = pd.DataFrame(results, columns=['Model', 'Sensitivity', 'Specificity', 'Precision', 'Recall', 'F1', 'Accuracy'])\n", "df_results"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 2}